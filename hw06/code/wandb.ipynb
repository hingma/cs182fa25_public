{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Tooling with Weights and Biases\n",
    "Similar to tensorboard, weights and biases is an application that tracks all your training metrics, and performs visualizations for you. This tool allows you to cleanly sort, organize, and visualize your experiments. In this notebook, we will go through an example of how to use wandb.ai and have you practice.\n",
    "\n",
    "1. Make an account at https://wandb.ai/site\n",
    "\n",
    "2. pip install wandb\n",
    "\n",
    "3. wandb login\n",
    "\n",
    "4. After step 3, please paste your wandb API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hingma/cs182fa25_public.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/hw06/code/'\n",
      "/Users/mox/Study/UCB/CS/CS182/cs182fa25_public/hw06/code\n"
     ]
    }
   ],
   "source": [
    "%cd /hw06/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import wandb\n",
    "from architectures import BasicConvNet, ResNet18, MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing wandb Projects\n",
    "\n",
    "With each run, you will want to have a set of parameters associated with it. For example, I want to be able to log different hyperparameters that I am using, so let's clearly list them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'CS182 WANDB.AI Practice Notebook'\n",
    "learning_rate = 0.01\n",
    "epochs = 2\n",
    "architecture ='CNN'\n",
    "dataset = 'CIFAR-10'\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "log_freq = 20\n",
    "print_freq = 200\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=project,\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": architecture,\n",
    "    \"dataset\": dataset,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"momentum\": momentum\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, we have some standard CIFAR training definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with wandb\n",
    "\n",
    "As you can see, similar to tensorboard, each gradient step we will want to log the accuracy and loss. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = torch.mean((torch.argmax(outputs, dim=1) == labels).float()).item() * 100\n",
    "\n",
    "        # print statistics\n",
    "        running_acc += accuracy\n",
    "        running_loss += loss.item()\n",
    "        if i % log_freq == log_freq - 1:\n",
    "            wandb.log({'accuracy': accuracy, 'loss': loss.item()})\n",
    "            \n",
    "        if i % print_freq == print_freq - 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.5f} accuracy: {running_acc/print_freq:.5f}')\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are done with this run, we will want to call \n",
    " `wandb.finish()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task\n",
    "We will be once again building classifiers for the CIFAR-10. There are various architectures set up for you to use in the architectures.py file. Using wandb, please search through 10 different hyperparameter configurations. Examples of choices include: learning rate, batch size, architecture, optimization algorithm, etc. Please submit the hyperparameters that result in the highest accuracies for this classification task. Please then explore wandb for all the visualization that you may need. In addition, feel free to run as many epochs as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(params):\n",
    "    # Extract parameters\n",
    "    learning_rate = params.get('learning_rate', 0.01)\n",
    "    architecture = params.get('architecture', 'BasicConvNet')\n",
    "    batch_size = params.get('batch_size', 64)\n",
    "    epochs = params.get('epochs', 5)\n",
    "    momentum = params.get('momentum', 0.9)\n",
    "    optimizer_name = params.get('optimizer', 'sgd')\n",
    "    weight_decay = params.get('weight_decay', 0)\n",
    "    log_freq = 20\n",
    "    print_freq = 200\n",
    "    resize_for_resnet = architecture == 'ResNet18'  # ResNet18 requires 224x224 images\n",
    "    \n",
    "    # Set device\n",
    "    cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    \n",
    "    # Initialize wandb\n",
    "    run = wandb.init(\n",
    "        project='CS182 CIFAR-10 Hyperparameter Search',\n",
    "        config=params,\n",
    "        reinit=True  # Allow multiple runs in the same process\n",
    "    )\n",
    "    \n",
    "    # Create transformations for data\n",
    "    transform_list = [transforms.ToTensor()]\n",
    "    if resize_for_resnet:\n",
    "        transform_list.insert(0, transforms.Resize((224, 224)))\n",
    "    transform_list.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    # Load datasets\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Create the model based on architecture parameter\n",
    "    if architecture == 'BasicConvNet':\n",
    "        net = BasicConvNet()\n",
    "    elif architecture == 'ResNet18':\n",
    "        net = ResNet18()\n",
    "    elif architecture == 'MLP':\n",
    "        hidden_layers = params.get('hidden_layers', 7)\n",
    "        hidden_size = params.get('hidden_size', 2048)\n",
    "        net = MLP(num_layers=hidden_layers, size=hidden_size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    net = net.to(device)\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Choose optimizer based on parameter\n",
    "    if optimizer_name.lower() == 'sgd':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, \n",
    "                             momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer_name.lower() == 'adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate, \n",
    "                             weight_decay=weight_decay)\n",
    "    elif optimizer_name.lower() == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, \n",
    "                                weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    # Optional: learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, 'min', patience=1, factor=0.5) if params.get('use_scheduler', False) else None\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # Get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # For MLP, we need to flatten the inputs\n",
    "            if architecture == 'MLP':\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = torch.mean((torch.argmax(outputs, dim=1) == labels).float()).item() * 100\n",
    "\n",
    "            # Log statistics\n",
    "            running_acc += accuracy\n",
    "            running_loss += loss.item()\n",
    "            if i % log_freq == log_freq - 1:\n",
    "                wandb.log({'train_accuracy': accuracy, 'train_loss': loss.item()})\n",
    "                \n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.5f} accuracy: {running_acc/print_freq:.5f}')\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "        \n",
    "        # Evaluation phase\n",
    "        net.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # For MLP, we need to flatten the inputs\n",
    "                if architecture == 'MLP':\n",
    "                    images = images.view(images.size(0), -1)\n",
    "                \n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_test_accuracy = 100 * correct / total\n",
    "        epoch_test_loss = test_loss / len(testloader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} Test Accuracy: {epoch_test_accuracy:.2f}%')\n",
    "        \n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'test_accuracy': epoch_test_accuracy,\n",
    "            'test_loss': epoch_test_loss\n",
    "        })\n",
    "        \n",
    "        # Update best accuracy\n",
    "        if epoch_test_accuracy > best_accuracy:\n",
    "            best_accuracy = epoch_test_accuracy\n",
    "        \n",
    "        # Update learning rate if using scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_test_loss)\n",
    "    \n",
    "    # Log best accuracy as summary metric\n",
    "    wandb.run.summary['best_accuracy'] = best_accuracy\n",
    "    \n",
    "    # Finish the wandb run\n",
    "    wandb.finish()\n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter configurations to try\n",
    "hyperparameter_configs = [\n",
    "    {'architecture': 'BasicConvNet', 'learning_rate': 0.01, 'batch_size': 64, 'epochs': 10, 'optimizer': 'sgd', 'momentum': 0.9},\n",
    "    {'architecture': 'BasicConvNet', 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'},\n",
    "    {'architecture': 'ResNet18', 'learning_rate': 0.01, 'batch_size': 64, 'epochs': 10, 'optimizer': 'sgd', 'momentum': 0.9},\n",
    "    {'architecture': 'ResNet18', 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 10, 'optimizer': 'adam'},\n",
    "    {'architecture': 'MLP', 'learning_rate': 0.01, 'batch_size': 64, 'epochs': 10, 'optimizer': 'sgd', 'momentum': 0.9, 'hidden_layers': 5, 'hidden_size': 1024},\n",
    "    {'architecture': 'MLP', 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 10, 'optimizer': 'adam', 'hidden_layers': 3, 'hidden_size': 2048},\n",
    "    {'architecture': 'BasicConvNet', 'learning_rate': 0.005, 'batch_size': 32, 'epochs': 10, 'optimizer': 'rmsprop'},\n",
    "    {'architecture': 'ResNet18', 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 10, 'optimizer': 'adam', 'weight_decay': 1e-4},\n",
    "    {'architecture': 'BasicConvNet', 'learning_rate': 0.01, 'batch_size': 64, 'epochs': 10, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 1e-4, 'use_scheduler': True},\n",
    "    {'architecture': 'ResNet18', 'learning_rate': 0.01, 'batch_size': 128, 'epochs': 10, 'optimizer': 'sgd', 'momentum': 0.95, 'weight_decay': 5e-4, 'use_scheduler': True}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each configuration and track results\n",
    "results = []\n",
    "for i, config in enumerate(hyperparameter_configs):\n",
    "    print(f\"Running configuration {i+1}/10: {config}\")\n",
    "    accuracy = run(config)\n",
    "    results.append((config, accuracy))\n",
    "    print(f\"Configuration {i+1} finished with best accuracy: {accuracy:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Sort and display results\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nBest hyperparameter configurations:\")\n",
    "for i, (config, accuracy) in enumerate(results[:3]):\n",
    "    print(f\"{i+1}. Accuracy: {accuracy:.2f}%, Config: {config}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This software/tutorial is based on PyTorch, an open-source project available at https://github.com/pytorch/tutorials/\n",
    "\n",
    "There is a BSD 3-Clause License as seen here: https://github.com/pytorch/tutorials/blob/main/LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
